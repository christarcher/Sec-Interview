### 了解 TF-IDF 文档匹配算法吗

**TF-IDF 的核心思想**

TF-IDF 的核心思想可以用一句话概括：**一个词语在一个文档中出现得越多，并且在所有文档中出现得越少，那么它对于该文档的区分度就越高，也就越重要**

这个算法将一个词语的重要性分为两个部分来计算：

**1. 词频**

**TF** 表示一个词语在一个文档中出现的频率。计算公式通常是：

TF(t,d)=文档 d 中所有词语的总数词语 t 在文档 d 中出现的次数

- **作用**：衡量一个词语在**当前文档**中的重要性。一个词在文档中出现得越多，TF 值就越大，表明该词与该文档的相关性可能更高。

**2. 逆文档频率（IDF, Inverse Document Frequency）**

**IDF** 表示一个词语在整个文档集中出现的稀有程度。计算公式通常是：

IDF(t,D)=log(包含词语 t 的文档数+1文档总数 N)

这里的 +1 是为了防止分母为零，以避免对未出现的词语产生错误计算。

- **作用**：衡量一个词语在**所有文档**中的重要性。
  - 如果一个词语在很多文档中都出现，说明它是一个**通用词**（如“的”、“是”、“了”），它的 IDF 值就会很低，接近于0。
  - 如果一个词语只在很少的文档中出现，说明它是一个**稀有词**，它的 IDF 值就会很高。

**TF-IDF 的计算**

最终，一个词语在一个文档中的 **TF-IDF 值**是 **TF** 和 **IDF** 的乘积：

TF−IDF(t,d,D)=TF(t,d)×IDF(t,D)

**举个例子**

假设我们有一个包含3个文档的文档集：

- **文档1**：`“我 喜欢 吃 苹果。苹果 很甜。”`
- **文档2**：`“我 喜欢 吃 香蕉。”`
- **文档3**：`“我 喜欢 玩 电脑。”`

现在，我们来计算“**苹果**”这个词在**文档1**中的 TF-IDF 值

1. **计算 TF (苹果, 文档1)**
   - “苹果”在文档1中出现了2次
   - 文档1中总共有7个词语
   - TF=72≈0.286
2. **计算 IDF (苹果, 所有文档)**
   - 文档总数 N=3
   - “苹果”只出现在文档1中，所以包含“苹果”的文档数是1
   - IDF=log(1+13)=log(1.5)≈0.176
3. **计算 TF-IDF (苹果, 文档1)**
   - TF−IDF=0.286×0.176≈0.0503

如果再计算“**我**”这个词在**文档1**中的 TF-IDF 值：

1. **计算 TF (我, 文档1)**
   - “我”出现了1次
   - TF=71≈0.143
2. **计算 IDF (我, 所有文档)**
   - 文档总数 N=3
   - “我”出现在了所有3个文档中
   - IDF=log(3+13)=log(0.75)≈−0.125
3. **计算 TF-IDF (我, 文档1)**
   - TF−IDF=0.143×(−0.125)≈−0.0178

这个负值表明“我”这个词的通用性太高，几乎不具备区分度。而“苹果”这个词的 TF-IDF 值更高，因为它在文档1中频繁出现，但在整个文档集中又相对稀有，因此更能代表文档 1 的主题